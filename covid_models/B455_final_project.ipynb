{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lt603RpWfQ4W"
   },
   "source": [
    "# CSCI-B 455 Final Project\n",
    "## Author: Ben Duggan\n",
    "## Goal:\n",
    "\n",
    "Determine the total number of covid cases on a certain day for a given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yagsBHBnfGTH"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, urllib, tarfile, requests, datetime\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bCMFwifGzD5e",
    "outputId": "fd213f23-a27c-42be-c811-4b496c0c7f44"
   },
   "outputs": [],
   "source": [
    "# Download the covid and population data\n",
    "\n",
    "# Load NY-Times Covid data\n",
    "covid_data_url=\"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\"\n",
    "dtypes = {'date':'string', 'county':'string', 'state':'string', 'fips':'float64', 'cases':'int64', 'deaths':'float64'}\n",
    "covid_county_raw=pd.read_csv(covid_data_url, dtype=dtypes)\n",
    "\n",
    "# Load population county data from the US Census\n",
    "population_county_url=\"https://gist.githubusercontent.com/BenSDuggan/58c3e0e1cefaa4b8ac49209ef54ffa75/raw/ac6ed2cfabc0ee954e75db4014ddc2b3de677035/pop_2010-19.csv\"\n",
    "population_county_raw=pd.read_csv(population_county_url)\n",
    "\n",
    "# Load population data from the US Census\n",
    "population_state_url=\"https://gist.githubusercontent.com/BenSDuggan/4a5d357fc224247651692a8641b84530/raw/3d750e7acc00c024332966c09037edb6746845b9/pop_state_2010-19.csv\"\n",
    "population_state_raw=pd.read_csv(population_state_url)\n",
    "\n",
    "# Load combined Hopkins data that has population built in\n",
    "dtypes = {'Case_Type':'string', 'People_Total_Tested_Count':'float64', 'Cases':'int64', 'Difference':'int64', 'Date':'string', 'Combined_Key':'string', 'Country_Region':'string', 'Province_State':'string', 'Admin2':'string','iso2':'string','iso3':'string', 'FIPS':'float64', 'Lat':'float64', 'Long':'float64', 'Population_Count':'float64', 'People_Hospitalized_Cumulative_Count':'float64', 'Data_Source':'string', 'Prep_Flow_Runtime':'string'}\n",
    "combined_data_raw = pd.read_csv('https://query.data.world/s/sadhsnfk2xnj5fwpkawqxyx5j3qtf4', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKym7x-xGcNu"
   },
   "outputs": [],
   "source": [
    "# Create helpful dictionaries\n",
    "\n",
    "# Find when each state had its first case\n",
    "state_first_case = {}\n",
    "\n",
    "for i in range(covid_county_raw.shape[0]):\n",
    "  curr = covid_county_raw.loc[i,:]\n",
    "  if curr['state'] not in state_first_case:\n",
    "    state_first_case[curr['state']] = curr['date']\n",
    "\n",
    "# Get state population\n",
    "state_pop = {}\n",
    "for i in range(population_state_raw.shape[0]):\n",
    "  state_pop[population_state_raw['NAME'][i]] = population_state_raw['POPESTIMATE2019'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUYuYFZxPdmk"
   },
   "outputs": [],
   "source": [
    "# Process combined data (not actuall used)\n",
    "\n",
    "# Drop results outside the US\n",
    "combined_data = combined_data_raw.copy()\n",
    "combined_data = combined_data[combined_data['FIPS'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wF7OTYqfvNRP"
   },
   "outputs": [],
   "source": [
    "# Generate list of state data from Johns Hopkins data\n",
    "\n",
    "# Range of dates to get\n",
    "state_date = datetime.datetime(2020, 4, 12)\n",
    "curr_date = state_date\n",
    "end_date = '05-05-2020' # Exclusive\n",
    "\n",
    "last_cases, last_deaths = {}, {}\n",
    "\n",
    "# The dataframe we want to create\n",
    "header = ['date', 'state', 'fips', 'cases', 'ncases', 'deaths', 'ndeaths', 'first_case_date', 'days_from_first_case', 'pop', 'Incident_Rate', 'People_Tested', 'People_Hospitalized', 'Mortality_Rate', 'Testing_Rate', 'Hospitalization_Rate']\n",
    "covid_state_raw = pd.DataFrame(None, columns = header) \n",
    "\n",
    "while curr_date.strftime(\"%m-%d-%Y\") != end_date:\n",
    "  curr_raw = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/%s.csv' % curr_date.strftime(\"%m-%d-%Y\"))\n",
    "  \n",
    "  rows = curr_raw.shape[0]\n",
    "  row = {}\n",
    "  \n",
    "  row['date'] = [curr_date.strftime('%y-%m-%d')] * rows\n",
    "  row['state'] = curr_raw['Province_State'].tolist()\n",
    "  row['fips'] = curr_raw['FIPS'].tolist()\n",
    "  row['cases'] = curr_raw['Confirmed'].tolist()\n",
    "  row['deaths'] = curr_raw['Deaths'].tolist()\n",
    "  row['Incident_Rate'] = curr_raw['Incident_Rate']\n",
    "  row['People_Tested'] = curr_raw['People_Tested']\n",
    "  row['People_Hospitalized'] = curr_raw['People_Hospitalized']\n",
    "  row['Mortality_Rate'] = curr_raw['Mortality_Rate']\n",
    "  row['Testing_Rate'] = curr_raw['Testing_Rate']\n",
    "  row['Hospitalization_Rate'] = curr_raw['Hospitalization_Rate']\n",
    "  row['pop'] = []\n",
    "  row['first_case_date'] = []\n",
    "  row['days_from_first_case'] = []\n",
    "  row['ncases'] = []\n",
    "  row['ndeaths'] = []\n",
    "  for i in range(rows):\n",
    "    if curr_raw['Province_State'][i] in state_pop:\n",
    "      row['pop'].append(state_pop[curr_raw['Province_State'][i]])\n",
    "    else:\n",
    "      row['pop'].append(float(\"NaN\"))\n",
    "    if curr_raw['Province_State'][i] in state_first_case:\n",
    "      row['first_case_date'].append(state_first_case[curr_raw['Province_State'][i]])\n",
    "      row['days_from_first_case'].append(int((curr_date - datetime.datetime.strptime(state_first_case[curr_raw['Province_State'][i]], '%Y-%m-%d')).days))\n",
    "    else:\n",
    "      row['first_case_date'].append(float(\"NaN\"))\n",
    "      row['days_from_first_case'].append(float(\"NaN\"))\n",
    "    if curr_raw['Province_State'][i] in last_cases:\n",
    "      row['ncases'].append(curr_raw['Confirmed'][i] - last_cases[curr_raw['Province_State'][i]])\n",
    "      last_cases[curr_raw['Province_State'][i]] = curr_raw['Confirmed'][i]\n",
    "    else:\n",
    "      last_cases[curr_raw['Province_State'][i]] = curr_raw['Confirmed'][i]\n",
    "      row['ncases'].append(0)\n",
    "    if curr_raw['Province_State'][i] in last_deaths:\n",
    "      row['ndeaths'].append(curr_raw['Deaths'][i] - last_deaths[curr_raw['Province_State'][i]])\n",
    "      last_deaths[curr_raw['Province_State'][i]] = curr_raw['Deaths'][i]\n",
    "    else:\n",
    "      last_deaths[curr_raw['Province_State'][i]] = curr_raw['Deaths'][i]\n",
    "      row['ndeaths'].append(0)\n",
    "  try:\n",
    "    covid_state_raw = pd.concat([covid_state_raw, pd.DataFrame(row, columns = header)], ignore_index = True)\n",
    "  except:\n",
    "    print('Error with : ')\n",
    "    print(curr_date)\n",
    "    \n",
    "  curr_date += datetime.timedelta(days=1)\n",
    "\n",
    "combined_state_data = covid_state_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdkqLSUNsmJB"
   },
   "outputs": [],
   "source": [
    "# Start of model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2hM0_gCwjYm"
   },
   "outputs": [],
   "source": [
    "# Create data for Model 1\n",
    "\n",
    "# Create an X and Y variable\n",
    "\n",
    "csd = combined_state_data.copy()\n",
    "csd = csd.loc[:, ['deaths', 'ndeaths', 'pop', 'days_from_first_case', 'Testing_Rate', 'cases']]\n",
    "\n",
    "# Remove nan values\n",
    "csd = csd.dropna()\n",
    "\n",
    "# Randomize\n",
    "np.random.seed(0)\n",
    "csd = csd.reindex(np.random.permutation(csd.index))\n",
    "\n",
    "# Get main vars\n",
    "y = csd['cases'].tolist()\n",
    "X = csd.drop('cases', axis=1).to_numpy()\n",
    "X.astype(float)\n",
    "\n",
    "# Normalize\n",
    "#row_sums = X.sum(axis=1)\n",
    "#X = X / row_sums[:, np.newaxis]\n",
    "\n",
    "# Break into testing and training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e_x6Lr1RKcCF",
    "outputId": "1c7541de-c3a6-481a-db04-ca2986cdeb37"
   },
   "outputs": [],
   "source": [
    "# Train and test regression model\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "scores = cross_val_score(lm, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqkHLqdewjce"
   },
   "outputs": [],
   "source": [
    "# Create data for Model 2\n",
    "\n",
    "# Create an X and Y variable\n",
    "\n",
    "csd = combined_state_data.copy()\n",
    "csd = csd.loc[:, ['deaths', 'ndeaths', 'pop', 'days_from_first_case', 'Testing_Rate', 'ncases']]\n",
    "\n",
    "# Remove nan values\n",
    "csd = csd.dropna()\n",
    "\n",
    "# Randomize\n",
    "np.random.seed(0)\n",
    "csd = csd.reindex(np.random.permutation(csd.index))\n",
    "\n",
    "# Get main vars\n",
    "y = csd['ncases'].tolist()\n",
    "X = csd.drop('ncases', axis=1).to_numpy()\n",
    "X.astype(float)\n",
    "\n",
    "# Normalize\n",
    "#row_sums = X.sum(axis=1)\n",
    "#X = X / row_sums[:, np.newaxis]\n",
    "\n",
    "# Break into testing and training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eWdgXqz_s9st",
    "outputId": "58729aa5-cd17-415e-d704-438356732f6b"
   },
   "outputs": [],
   "source": [
    "# Train and test regression model\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "scores = cross_val_score(lm, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9cvqP-4YaBnR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JeakIYZZyjv1"
   },
   "source": [
    "\n",
    "# CSCI-B 455 Final Project\n",
    "\n",
    "## Introduction\n",
    "\n",
    "COVID-19 is a world wide pandemic effecting almost everyone around the world in someway.  The United States of America has been hit hard with 1,237,633 cases at the time of submission (worldometer, https://www.worldometers.info/coronavirus/country/us/).  No one knows when the pandemic will end, what ever that looks like (no more social distancing, for example).  Some think that the virus will only end when we get a vacination.  Regardless, it is useful to be able to predict the number of coronavirus cases in a state.\n",
    "\n",
    "The number of cases will obveously be increasing (or at least not decreasing), and the rate of increase is quite easy to see.  However, putting an exact number on this is more difficult.  This number can be estimated quite well by using the number of deaths, which lag the number of cases (Thomas Pueyo, https://medium.com/@tomaspueyo/coronavirus-act-today-or-people-will-die-f4d3d9cd99ca)(Khan Academy, https://www.youtube.com/watch?v=mCa0JXEwDEk).\n",
    "\n",
    "Testing capability is also likely related to the number of cases.  If you can't test then you can't confirm a coronavirus case.  The date that a state first had a coronavirus case is likely important.  Lastly, the population of the state is important for estimateing the current number of cases in a state.\n",
    "\n",
    "## Datasets\n",
    "\n",
    "The five features I used is number of deaths, number of days since first death, population of state, days since first case, and the testing rate.  Each datapoint is from a particular state on a particular day.  To create this dataset I assembled data from three sources.\n",
    "\n",
    "The data primarily came from \"COVID-19 Data Repository\" by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University hosted on GitHub at <https://github.com/CSSEGISandData/COVID-19>.  I'm using the `csse_covid_19_daily_reports_us` folder which contains data about each state collected each day from 4/14/2020 till today 5/4/2020.  There is a lot of useful data but I'm using the confirmed cases, deaths, and the testing rate.  To find the first test date, I used the New York Times county data to find the first date that a state recorded a cornoavirus case.  I then find the number of days from that when creating the dataset.  The dataset can be found here: <https://github.com/nytimes/covid-19-data/blob/master/us-counties.csv>.  I needed to use this data because it goes back all the way to when the virus entred the USA.  The last dataset I used was was the state population from 2019 found here <https://www.census.gov/data/tables/time-series/demo/popest/2010s-state-total.html>.\n",
    "\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "Some of the datasets were uploaded to a GitHub Gist to make it easier to load into Google CodeLabs.  Once downloading the data I found the first day COVID-19 was found in a particular state.  Then for each day in the Johns Hopkins data, I extracted the total cases, total deaths, and testing rate for that day.  I calculated the days since first seeing coronavirus and added that to the datapoint.  Finally, I calculated the number of new COVID cases and deaths (using the previous day as a base) and added this to the dataset.\n",
    "\n",
    "While this may bias the data somehow, I think this method of dataprocessing allows for a lot of data to be producesd from little, time series information.  After creating the dataset, I dropped all rows that had missing data and randomized the data.\n",
    "  \n",
    "## Models and analysis\n",
    "\n",
    "Scikit Learn was used to construct the models.  I built two different regression models.  Both models were evaluated using 5-fold cross validation.  I chose to use regression as my output attribute is continuous.  Additionally, it is quick to train models.\n",
    "\n",
    "The first model used Linear Regression and total number of cases as the output attribute.  I didn't have great hope for this model, as I only had 1,173 observations.  I initially normalized the data and got a result of around 73% with a standard deviation of around 10%.  When I tried the model without normalization, I got an accuracy of 98% with a standard deviation of 1%.  I didn't think I could get a better accuracy than this, but I was currious how the model would train with number of new cases as the output feature.\n",
    "\n",
    "The second model used the same regression model but number of new cases as the output attribute.  I thought this model would be better as predicting the number of new cases seems more difficult to me.  Giving the change seems like it would be easier.  When I trained the model, using the `Linear_Regression` moduel, and didn't normalize the data.  I got an accuracy of 63% with a standard deviation of 30%.  This model doesn't perform well at all.  \n",
    "\n",
    "## Discussion\n",
    "\n",
    "I was surprised by a lot of parts of this project.  The data collection and processing definetly took me the longest ammount of time.  It was hard to find a good sourse of COVID-19 data that was large enough to train a model with.  Initially, I wanted to look at county data, however, there was no where near enough data for that.  I settled on using the States which likely helped me because outlier county with high cases were removed.\n",
    "\n",
    "I'm surprised that Model 1 worked as well as it did.  This might have been from incorperating death as one of the features.  I don't think this is bad, but the numbers are very much related.  Still, 98% accuracy seems too good to be true.  However, I think that you can predict the number of cases in a state, for a certain day, using deaths, number of new deaths, population, testing ratio, and days from first test.  My method seems to be very sucessful in predicting the number of new cases.  The number of new cases cannot be accurately predicted, however, using the same features.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "B455_final-project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
